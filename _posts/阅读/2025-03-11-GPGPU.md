---
layout: post
title: GPGPU
date: 2025-1-8 19:22 +0800
categories: [读书笔记, 资料检索]
tags: []
math: true
img_path: /assets/img/learn/
---

在三维的位置看矩阵乘法

![matr_pos]({{ page.img_path }}matr_pos.png){: width="400" height="auto" }


## vortex笔记

### 1. Wavefront Scheduler

1) a set of wavefront masks  
2) a wavefront table that includes privated information for each wavefront. 

The scheduler uses four thread masks: 
1) an active wavefront mask
2) a stalled wavefront mask indicates which warps should not be scheduled temporarily,
3) a barrierd mask for stalled wavefronts waiting at a barrier instruction
4) a visible wavefront mask to support hierarchical scheduling policy . 

在每个周期中，调度器从visible wavefront mask中选择一个wavefront，并将该wavefront标记为无效。当visible wavefront mask全为零时，通过检查当前哪些wavefront处于`活跃且未被阻塞状态`来重新填充活跃掩码。



### 2. 线程掩码（Thread Mask）和IPDOM栈来处理分支分歧（divergence）


**IPDOM栈**   一个硬件栈结构，用于保存分支分歧时的上下文信息（如线程掩码、程序计数器PC等）

**当执行`split`指令时（如遇到分支分歧）**：
1) 将当前活跃线程的掩码压入IPDOM栈，标记为`fall-through(else的指令)`
2) 检查每个线程的predicate，“条件为假”的线程会被推入IPDOM栈，栈条目包含这些线程的掩码和分支目标地址（`next PC`，即条件为假时分支的起始地址，如`else`块的入口）
3) 更新线程掩码，仅保留条件为真的线程，继续执行if内的代码块

例子：

```c
if (x > 0) { // split指令
    A();     // True分支
} else {
    B();     // False分支
}
C();         // 收敛点（join）
- 将当前所有活跃线程的掩码作为`fall-through`压栈，对应A->C
- 将`False`线程的掩码和`B()`的入口地址压栈
- 掩码更新为`True`的线程，执行`A()`

- 如果A()执行->join,弹出`False`线程的掩码和`B()`的入口地址
- 反之，弹出`fall-through`，恢复所有线程活跃，继续执行C
```

### 3. Wavefront Barriers

（1）Barrier Table：

- **计数器（Counter）**：记录尚未到达该屏障的Wavefront数量。
- **阻塞掩码（Stalled Mask）**：记录因等待该屏障而被阻塞的Wavefront。

- **初始状态**：4个Wavefront需要同步。
    - **计数器**=4，**阻塞掩码**=0000（无阻塞）。
- **Wavefront执行屏障指令**：
    1. **计数器减1**：例如第一个Wavefront到达后，计数器变为3。
    2. **阻塞当前Wavefront**：将对应掩码位置1（如0001）。
- **所有Wavefront到达时**（计数器=0）：
    - 释放所有被阻塞的Wavefront（掩码清零），恢复执行。

（2）Global Barriers：多核配置

barrier ID的MSB=1代表全局屏障（需所有核心的Wavefront参与）， MSB=0：本核心内的屏障。


### 4. Hardware Texture Filtering

硬件实现了可配置的纹理单元（texture unit）以支持图形处理，每个纹理单元在给定的(u, v)源坐标和指定纹理细节层级的lod操作数上，实现纹理的点采样和双线性采样。高级Filtering算法如trilinear or anisotropic filtering则以伪指令形式实现。








## append、GPU的基础知识点

一个简易版本的架构区别：

![cpu_gpu]({{ page.img_path }}cpu_gpu.png){: width="400" height="auto" }

GPU索引包含blockIdx和threadIdx，blockIdx是在线程之间共享的 


-**Warps** ：The PC is shared; maintain thread mask for Writeback，同一warp内所有线程共用一个程序计数器（PC），因此它们在同一时刻执行相同的指令。由于条件分支或其他条件，GPU会维护一个线程掩码，在执行写回（Writeback）阶段时，只有那些处于活动状态的线程会将计算结果写回到寄存器或内存中。

there are thread groups that share control units，and those are streaming multiprocessors.  the core components of our gpu

![gpu_archi1]({{ page.img_path }}gpu_archi1.png){: width="400" height="auto" }
![gpu_archi2]({{ page.img_path }}gpu_archi2.png){: width="400" height="auto" }
![gpu_archi3]({{ page.img_path }}gpu_archi3.png){: width="400" height="auto" }
![gpu_archi4]({{ page.img_path }}gpu_archi4.png){: width="400" height="auto" }
![gpu_archi5]({{ page.img_path }}gpu_archi5.png){: width="400" height="auto" }
![gpu_archi6]({{ page.img_path }}gpu_archi6.png){: width="400" height="auto" }

1. Raster Engine
2. ROP
3. PolyMorph Engine
4. RT core
5. TEX unit
6. Warp Scheduler
7. Dispatch Unit
8. SFU
